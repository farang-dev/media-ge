name: Daily Article Scraper

on:
  schedule:
    # Run daily at 7:00 AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch:  # Allows manual triggering from GitHub UI

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Create .env file
        run: |
          echo "Creating .env file with secrets..."
          echo "WORDPRESS_API_URL=${{ secrets.WORDPRESS_API_URL }}" > .env
          echo "WORDPRESS_CLIENT_ID=${{ secrets.WORDPRESS_CLIENT_ID }}" >> .env
          echo "WORDPRESS_CLIENT_SECRET=${{ secrets.WORDPRESS_CLIENT_SECRET }}" >> .env
          echo "WORDPRESS_USERNAME=${{ secrets.WORDPRESS_USERNAME }}" >> .env
          echo "WORDPRESS_PASSWORD=${{ secrets.WORDPRESS_PASSWORD }}" >> .env
          echo "OPENROUTER_API_KEY=${{ secrets.OPENROUTER_API_KEY }}" >> .env
          echo "NEXT_PUBLIC_SITE_URL=${{ secrets.NEXT_PUBLIC_SITE_URL }}" >> .env
          echo "Created .env file with the following variables:"
          cat .env | grep -v PASSWORD | grep -v SECRET | grep -v KEY

      - name: Run article scraper and publisher
        run: node scripts/test-full-process.js
