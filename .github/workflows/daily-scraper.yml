name: Daily Article Scraper

on:
  schedule:
    # Run at 7:00 AM UTC every day
    # Adjust the timezone as needed (e.g., "0 7 * * *" for 7:00 AM UTC)
    - cron: '0 7 * * *'
  workflow_dispatch:  # This allows manual triggering from the GitHub UI

  # Run this workflow when changes are pushed to the master branch
  push:
    branches: [master]
    paths:
      - 'scripts/**'
      - 'lib/**'
      - '.github/workflows/daily-scraper.yml'

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run scraper script
      run: node scripts/test-full-process.js
      env:
        # Add all your environment variables here
        WORDPRESS_API_URL: ${{ secrets.WORDPRESS_API_URL }}
        WORDPRESS_USERNAME: ${{ secrets.WORDPRESS_USERNAME }}
        WORDPRESS_API_KEY: ${{ secrets.WORDPRESS_API_KEY }}
        WORDPRESS_CLIENT_ID: ${{ secrets.WORDPRESS_CLIENT_ID }}
        WORDPRESS_CLIENT_SECRET: ${{ secrets.WORDPRESS_CLIENT_SECRET }}
        WORDPRESS_PASSWORD: ${{ secrets.WORDPRESS_PASSWORD }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        NEXT_PUBLIC_SITE_URL: ${{ secrets.NEXT_PUBLIC_SITE_URL }}

    - name: Generate sitemap
      run: node scripts/generate-sitemap.js
      env:
        WORDPRESS_API_URL: ${{ secrets.WORDPRESS_API_URL }}
        NEXT_PUBLIC_SITE_URL: ${{ secrets.NEXT_PUBLIC_SITE_URL }}

    - name: Commit and push sitemap changes
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add public/sitemap.xml
        git commit -m "Update sitemap with latest articles" || echo "No changes to commit"
        git push
